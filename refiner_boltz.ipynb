{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ed923f",
   "metadata": {},
   "source": [
    "## Protein Hunter Boltz (Refiner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üß© Setup and Core Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import contextlib\n",
    "import io\n",
    "import copy\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.*\",\n",
    "    category=UserWarning,\n",
    ")\n",
    "\n",
    "import py2Dmol\n",
    "from LigandMPNN.wrapper import LigandMPNNWrapper\n",
    "\n",
    "# --- New/Refactored Imports ---\n",
    "from boltz_ph.constants import CHAIN_TO_NUMBER\n",
    "from utils.metrics import get_CA_and_sequence # Used implicitly in design.py\n",
    "from utils.convert import calculate_holo_apo_rmsd, convert_cif_files_to_pdb\n",
    "# -----------------------------\n",
    "\n",
    "from boltz_ph.model_utils import (\n",
    "    binder_binds_contacts,\n",
    "    extract_sequence_from_structure,\n",
    "    clean_memory,\n",
    "    design_sequence,\n",
    "    get_boltz_model,\n",
    "    get_cif,\n",
    "    load_canonicals,\n",
    "    plot_from_pdb,\n",
    "    plot_run_metrics,\n",
    "    process_msa,\n",
    "    run_prediction,\n",
    "    sample_seq,\n",
    "    save_pdb,\n",
    "    shallow_copy_tensor_dict,\n",
    "    smart_split,\n",
    ")\n",
    "print(\"‚úÖ Core functionality imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üß¨ Boltz Configuration Parameters\n",
    "# --- General Setup ---\n",
    "gpu_id = 1  # @param {type:\"integer\"}\n",
    "grad_enabled = False  # @param {type:\"boolean\"}\n",
    "name = \"PDL1_refiner_02\"  # @param {type:\"string\"}\n",
    "mode = \"binder\"  # @param [\"unconditional\", \"binder\"]\n",
    "num_designs = 3  # @param {type:\"integer\"}\n",
    "num_cycles = 5  # @param {type:\"integer\"}\n",
    "save_dir = f\"./results_boltz_refiner/{name}\"\n",
    "work_dir = os.getcwd()\n",
    "\n",
    "\n",
    "# --- New Refiner/Cycling Input ---\n",
    "# Path to the initial CIF or PDB file to start the refinement from\n",
    "initial_design_path = \"/home/jupyter-yehlin/ProteinHunter/example/rank03_5c3tprot_1.cif\" ## e.g. cif or pdb file\n",
    "binder_chain = \"A\"  # @param {type:\"string\"}\n",
    "binder_seq = extract_sequence_from_structure(initial_design_path, binder_chain)\n",
    "cyclic = False  # @param {type:\"boolean\"}\n",
    "binder_length = len(binder_seq)\n",
    "\n",
    "# --- Target Protein(s) ---\n",
    "protein_ids = \"B\"  # @param {type:\"string\"}\n",
    "protein_seqs = extract_sequence_from_structure(initial_design_path, protein_ids)  # @param {type:\"string\"}\n",
    "protein_msas = (\n",
    "    \"\"  # \"\" means generate, \"empty\" is single sequence # @param {type:\"string\"}\n",
    ")\n",
    "\n",
    "# --- Non-Protein Components (Ligand/Nucleic Acid) ---\n",
    "ligand_id = \"C\"\n",
    "ligand_smiles = \"\"  # @param {type:\"string\"}\n",
    "ligand_ccd = \"\"  # @param {type:\"string\"}\n",
    "nucleic_type = \"dna\"\n",
    "nucleic_id = \"\"\n",
    "nucleic_seq = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# --- Templates and Constraints ---\n",
    "template_path = \"\"\n",
    "template_chain_id = \"\"\n",
    "add_constraints = False  # @param {type:\"boolean\"}\n",
    "contact_residues = \"\"  # e.g., \"1,2,5,10\" on target chain # @param {type:\"string\"}\n",
    "constraint_target_chain = \"B\"  # Target chain for contacts # @param {type:\"string\"}\n",
    "contact_cutoff = 10.0  # @param {type:\"number\"}\n",
    "max_contact_filter_retries = 6  # @param {type:\"integer\"}\n",
    "no_contact_filter = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# --- Model & Diffusion Parameters ---\n",
    "no_potentials = True  # @param {type:\"boolean\"}\n",
    "diffuse_steps = 200  # @param {type:\"integer\"}\n",
    "recycling_steps = 3  # @param {type:\"integer\"}\n",
    "boltz_model_version = \"boltz2\"  # @param [\"boltz1\", \"boltz2\"]\n",
    "boltz_model_path = os.path.expanduser(\"~/.boltz/boltz2_conf.ckpt\")\n",
    "ccd_path = Path(os.path.expanduser(\"~/.boltz/mols\"))\n",
    "logmd = False  # @param {type:\"boolean\"}\n",
    "\n",
    "# --- Design & Optimization ---\n",
    "randomly_kill_helix_feature = False  # @param {type:\"boolean\"}\n",
    "negative_helix_constant = 0.0  # @param {type:\"number\"}\n",
    "alanine_bias = True  # @param {type:\"boolean\"}\n",
    "temperature_start = 0.05  # @param {type:\"number\"}\n",
    "temperature_end = 0.001  # @param {type:\"number\"}\n",
    "alanine_bias_start = -0.5  # @param {type:\"number\"}\n",
    "alanine_bias_end = -0.2  # @param {type:\"number\"}\n",
    "omit_AA = \"C\"  # @param {type:\"string\"}\n",
    "exclude_P = False  # @param {type:\"boolean\"}\n",
    "high_iptm_threshold = 0.8  # @param {type:\"number\"}\n",
    "\n",
    "# --- Optional: Validation Parameters (External Dependencies) ---\n",
    "alphafold_dir = os.path.expanduser(\"~/alphafold3\")\n",
    "af3_docker_name = \"alphafold3_yc\"\n",
    "af3_database_settings = os.path.expanduser(\"~/alphafold3/alphafold3_data_save\")\n",
    "hmmer_path = os.path.expanduser(\"~/.conda/envs/alphafold3_venv\")\n",
    "use_msa_for_af3 = False\n",
    "plot = True  # @param {type:\"boolean\"}\n",
    "viewer = True  # @param {type:\"boolean\"}\n",
    "\n",
    "\n",
    "# Re-package parameters into an 'args' object (simple class for dot notation)\n",
    "class Args:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "args = Args(**locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title ‚öôÔ∏è Initialize Models and Prepare Base Data\n",
    "# --- 1. Model Initialization ---\n",
    "device = (\n",
    "    f\"cuda:{args.gpu_id}\" if torch.cuda.is_available() and args.gpu_id >= 0 else \"cpu\"\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "predict_args = {\n",
    "    \"recycling_steps\": args.recycling_steps,\n",
    "    \"sampling_steps\": args.diffuse_steps,\n",
    "    \"diffusion_samples\": 1,\n",
    "    \"write_confidence_summary\": True,\n",
    "    \"write_full_pae\": False,\n",
    "    \"write_full_pde\": False,\n",
    "    \"max_parallel_samples\": 1,\n",
    "}\n",
    "\n",
    "ccd_lib = load_canonicals(os.path.expanduser(str(args.ccd_path)))\n",
    "boltz_model = get_boltz_model(\n",
    "    checkpoint=args.boltz_model_path,\n",
    "    predict_args=predict_args,\n",
    "    device=device,\n",
    "    model_version=args.boltz_model_version,\n",
    "    no_potentials=args.no_potentials,\n",
    "    grad_enabled=args.grad_enabled,\n",
    ")\n",
    "designer = LigandMPNNWrapper(os.path.join(args.work_dir, \"./LigandMPNN/run.py\"))\n",
    "protein_hunter_save_dir = os.path.join(args.save_dir, \"0_protein_hunter_design\")\n",
    "os.makedirs(protein_hunter_save_dir, exist_ok=True)\n",
    "os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "# --- 2. Data Preparation (Condensed from _build_initial_data_dict) ---\n",
    "sequences = []\n",
    "# Process multi-chain/MSA inputs\n",
    "protein_ids_list = smart_split(args.protein_ids)\n",
    "protein_seqs_list = smart_split(args.protein_seqs)\n",
    "protein_msas_list = (\n",
    "    smart_split(args.protein_msas)\n",
    "    if args.protein_msas\n",
    "    else [\"\"] * len(protein_ids_list)\n",
    ")\n",
    "\n",
    "max_len = max(\n",
    "    len(protein_ids_list),\n",
    "    len(protein_seqs_list),\n",
    "    len(protein_msas_list),\n",
    ")\n",
    "for l in [protein_ids_list, protein_seqs_list, protein_msas_list]:\n",
    "    while len(l) < max_len:\n",
    "        l.append(\"\")\n",
    "\n",
    "seq_to_indices = defaultdict(list)\n",
    "for idx, seq in enumerate(protein_seqs_list):\n",
    "    if seq:\n",
    "        seq_to_indices[seq].append(idx)\n",
    "seq_to_final_msa = {}\n",
    "\n",
    "# Suppress MSA generation output during this phase\n",
    "with contextlib.redirect_stdout(io.StringIO()) as f:\n",
    "    for seq, idx_list in seq_to_indices.items():\n",
    "        chosen_msa = next(\n",
    "            (\n",
    "                protein_msas_list[i]\n",
    "                for i in idx_list\n",
    "                if protein_msas_list[i] and protein_msas_list[i] != \"empty\"\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        if chosen_msa is None:\n",
    "            chosen_msa = \"\"\n",
    "\n",
    "        if chosen_msa == \"\":\n",
    "            pid = (\n",
    "                protein_ids_list[idx_list[0]]\n",
    "                if protein_ids_list[idx_list[0]]\n",
    "                else f\"CHAIN_{idx_list[0]}\"\n",
    "            )\n",
    "            msa_value = process_msa(pid, seq, Path(protein_hunter_save_dir))\n",
    "            seq_to_final_msa[seq] = str(msa_value)\n",
    "        elif chosen_msa == \"empty\":\n",
    "            seq_to_final_msa[seq] = \"empty\"\n",
    "        else:\n",
    "            seq_to_final_msa[seq] = chosen_msa\n",
    "\n",
    "# Build sequences list and add X-binder\n",
    "for pid, seq in zip(protein_ids_list, protein_seqs_list):\n",
    "    if not pid or not seq:\n",
    "        continue\n",
    "    final_msa = seq_to_final_msa.get(seq, \"empty\")\n",
    "    sequences.append(\n",
    "        {\"protein\": {\"id\": [pid], \"sequence\": seq, \"msa\": final_msa}}\n",
    "    )\n",
    "sequences.append(\n",
    "    {\n",
    "        \"protein\": {\n",
    "            \"id\": [args.binder_chain],\n",
    "            \"sequence\": binder_seq,\n",
    "            \"msa\": \"empty\",\n",
    "            \"cyclic\": args.cyclic\n",
    "        }\n",
    "    }\n",
    ")\n",
    "if args.ligand_smiles:\n",
    "    sequences.append({\"ligand\": {\"id\": [args.ligand_id], \"smiles\": args.ligand_smiles}})\n",
    "elif args.ligand_ccd:\n",
    "    sequences.append({\"ligand\": {\"id\": [args.ligand_id], \"ccd\": args.ligand_ccd}})\n",
    "if args.nucleic_seq:\n",
    "    sequences.append(\n",
    "        {args.nucleic_type: {\"id\": [args.nucleic_id], \"sequence\": args.nucleic_seq}}\n",
    "    )\n",
    "\n",
    "# Handle templates and constraints\n",
    "templates = []\n",
    "if args.template_path:\n",
    "    template_path_list = smart_split(args.template_path)\n",
    "    template_chain_id_list = (\n",
    "        smart_split(args.template_chain_id) if args.template_chain_id else []\n",
    "    )\n",
    "    template_files = [get_cif(tp) for tp in template_path_list]\n",
    "    for i, template_file in enumerate(template_files):\n",
    "        t_block = (\n",
    "            {\"cif\": template_file}\n",
    "            if template_file.endswith(\".cif\")\n",
    "            else {\"pdb\": template_file}\n",
    "        )\n",
    "        if template_chain_id_list and i < len(template_chain_id_list):\n",
    "            t_block[\"chain_id\"] = template_chain_id_list[i]\n",
    "        templates.append(t_block)\n",
    "\n",
    "data = {\"sequences\": sequences}\n",
    "if templates:\n",
    "    data[\"templates\"] = templates\n",
    "pocket_conditioning = args.add_constraints\n",
    "\n",
    "if args.add_constraints:\n",
    "    residues = args.contact_residues.split(\",\")\n",
    "    contacts = [\n",
    "        [args.constraint_target_chain, int(res)]\n",
    "        for res in residues\n",
    "        if res.strip() != \"\"\n",
    "    ]\n",
    "    constraints = [{\"pocket\": {\"binder\": args.binder_chain, \"contacts\": contacts}}]\n",
    "    data[\"constraints\"] = constraints\n",
    "\n",
    "data[\"sequences\"] = sorted(\n",
    "    data[\"sequences\"], key=lambda entry: list(entry.values())[0][\"id\"][0]\n",
    ")\n",
    "\n",
    "any_ligand_or_nucleic = args.ligand_smiles or args.ligand_ccd or args.nucleic_seq\n",
    "model_type = \"ligand_mpnn\" if any_ligand_or_nucleic else \"soluble_mpnn\"\n",
    "\n",
    "print(\"‚úÖ Models ready and base data configured.\")\n",
    "print(\"Mode:\", args.mode)\n",
    "print(\"Data dictionary (base):\\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title üöÄ Execute Design and Optimization Loop (shortened)\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "def compute_iptm(pair_chains, ref_chain_idx):\n",
    "    if len(pair_chains) > 1:\n",
    "        vals = [\n",
    "            (\n",
    "                pair_chains[ref_chain_idx][i].detach().cpu().numpy()\n",
    "                + pair_chains[i][ref_chain_idx].detach().cpu().numpy()\n",
    "            ) / 2.0\n",
    "            for i in range(len(pair_chains)) if i != ref_chain_idx\n",
    "        ]\n",
    "        return float(np.mean(vals) if vals else 0.0)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def get_float(item, key, default_val):\n",
    "    return float(item.get(key, torch.tensor([default_val])).detach().cpu().numpy()[0])\n",
    "\n",
    "all_run_metrics = []\n",
    "\n",
    "for design_id in range(args.num_designs):\n",
    "    if viewer:\n",
    "        viewer = py2Dmol.view((600,400), color=\"plddt\")\n",
    "        viewer.show()\n",
    "\n",
    "    run_id = str(design_id)\n",
    "    run_save_dir = os.path.join(args.save_dir, f\"run_{run_id}\")\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "    data_cp = copy.deepcopy(data)\n",
    "    print(\"\\n\" + \"=\"*54)\n",
    "    print(f\"=== Starting Design Run {run_id}/{args.num_designs - 1} ===\")\n",
    "    print(\"=\"*54)\n",
    "\n",
    "    best_iptm, best_seq, best_structure, best_output, best_pdb_filename = float(\"-inf\"), None, None, None, None\n",
    "    best_cycle_idx, best_alanine_percentage = -1, None\n",
    "    run_metrics = {\"run_id\": run_id}\n",
    "    print(f\"Binder initial sequence length: {binder_length}\")\n",
    "\n",
    "    # --- Cycle 0 prediction ---\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        output, structure = run_prediction(\n",
    "            data_cp, args.binder_chain,\n",
    "            randomly_kill_helix_feature=args.randomly_kill_helix_feature,\n",
    "            negative_helix_constant=args.negative_helix_constant,\n",
    "            boltz_model=boltz_model, ccd_lib=ccd_lib, ccd_path=args.ccd_path,\n",
    "            logmd=args.logmd, device=device, boltz_model_version=args.boltz_model_version,\n",
    "            pocket_conditioning=pocket_conditioning,\n",
    "        )\n",
    "    pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_0.pdb\"\n",
    "    save_pdb(structure, output[\"coords\"], output[\"plddt\"].detach().cpu().numpy()[0], pdb_filename)\n",
    "    binder_chain_idx = CHAIN_TO_NUMBER[args.binder_chain]\n",
    "    cycle_0_iptm = compute_iptm(output[\"pair_chains_iptm\"], binder_chain_idx)\n",
    "    run_metrics.update({\n",
    "            \"cycle_0_iptm\": cycle_0_iptm,\n",
    "            \"cycle_0_plddt\": get_float(output, \"complex_plddt\", 0.0),\n",
    "            \"cycle_0_iplddt\": get_float(output, \"complex_iplddt\", 0.0),\n",
    "            \"cycle_0_alanine\": binder_seq.count(\"A\") if binder_length else 0.0,\n",
    "            \"cycle_0_seq\": binder_seq\n",
    "    })\n",
    "\n",
    "    # --- Cycles 1...N with sequence/structure optimization\n",
    "    for cycle in range(args.num_cycles):\n",
    "        print(f\"\\n--- Run {run_id}, Cycle {cycle + 1} ---\")\n",
    "        cycle_norm = (cycle / (args.num_cycles - 1)) if args.num_cycles > 1 else 0.0\n",
    "        alpha = args.alanine_bias_start - cycle_norm * (args.alanine_bias_start - args.alanine_bias_end)\n",
    "        temperature = args.temperature_start - cycle_norm * (args.temperature_start - args.temperature_end)\n",
    "        design_kwargs = {\n",
    "            \"pdb_file\": pdb_filename,\n",
    "            \"temperature\": temperature,\n",
    "            \"chains_to_design\": args.binder_chain,\n",
    "            \"omit_AA\": f\"{args.omit_AA},P\" if cycle == 0 else args.omit_AA,\n",
    "        }\n",
    "        if args.alanine_bias:\n",
    "            design_kwargs[\"bias_AA\"] = f\"A:{alpha}\"\n",
    "\n",
    "        seq_str, logits = design_sequence(designer, model_type, **design_kwargs)\n",
    "        seq = seq_str.split(\":\")[binder_chain_idx]\n",
    "        alanine_count = seq.count(\"A\")\n",
    "        alanine_percentage = alanine_count / binder_length if binder_length else 0.0\n",
    "        for seq_entry in data_cp[\"sequences\"]:\n",
    "            if \"protein\" in seq_entry and args.binder_chain in seq_entry[\"protein\"][\"id\"]:\n",
    "                seq_entry[\"protein\"][\"sequence\"] = seq\n",
    "                break\n",
    "\n",
    "        with contextlib.redirect_stdout(io.StringIO()):\n",
    "            output, structure = run_prediction(\n",
    "                data_cp, args.binder_chain, seq=seq,\n",
    "                randomly_kill_helix_feature=False, negative_helix_constant=0.0,\n",
    "                boltz_model=boltz_model, ccd_lib=ccd_lib, ccd_path=args.ccd_path,\n",
    "                logmd=False, device=device,\n",
    "            )\n",
    "        current_iptm = compute_iptm(output[\"pair_chains_iptm\"], binder_chain_idx)\n",
    "\n",
    "        if alanine_percentage <= 0.20 and current_iptm > best_iptm:\n",
    "            best_iptm, best_structure = current_iptm, copy.deepcopy(structure)\n",
    "            best_output = shallow_copy_tensor_dict(output)\n",
    "            best_pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_best_structure.pdb\"\n",
    "            save_pdb(best_structure, best_output[\"coords\"],\n",
    "                     best_output[\"plddt\"].detach().cpu().numpy()[0], best_pdb_filename)\n",
    "            best_cycle_idx, best_seq = cycle + 1, seq\n",
    "            best_alanine_percentage = alanine_percentage\n",
    "\n",
    "        curr_plddt = get_float(output, \"complex_plddt\", 0.0)\n",
    "        curr_iplddt = get_float(output, \"complex_iplddt\", 0.0)\n",
    "        run_metrics.update({\n",
    "            f\"cycle_{cycle + 1}_iptm\": current_iptm,\n",
    "            f\"cycle_{cycle + 1}_plddt\": curr_plddt,\n",
    "            f\"cycle_{cycle + 1}_iplddt\": curr_iplddt,\n",
    "            f\"cycle_{cycle + 1}_alanine\": alanine_count,\n",
    "            f\"cycle_{cycle + 1}_seq\": seq\n",
    "        })\n",
    "\n",
    "        print(f\"ipTM: {current_iptm:.2f}, pLDDT: {curr_plddt:.2f}, iPLDDT: {curr_iplddt:.2f}, Ala%: {alanine_percentage * 100:.1f}\")\n",
    "\n",
    "        pdb_filename = f\"{run_save_dir}/{args.name}_run_{run_id}_predicted_cycle_{cycle + 1}.pdb\"\n",
    "        save_pdb(structure, output[\"coords\"], output[\"plddt\"].detach().cpu().numpy()[0], pdb_filename)\n",
    "        if viewer:\n",
    "            viewer.add_pdb(pdb_filename)\n",
    "        clean_memory()\n",
    "\n",
    "    # --- Finalize & plot metrics\n",
    "    run_metrics.update({\n",
    "        \"best_iptm\": float(best_iptm if best_iptm != float(\"-inf\") else np.nan),\n",
    "        \"best_cycle\": best_cycle_idx,\n",
    "        \"best_seq\": best_seq,\n",
    "        \"best_plddt\": float(best_output.get(\"complex_plddt\", torch.tensor([np.nan])).detach().cpu().numpy()[0])\n",
    "            if best_output else np.nan\n",
    "    })\n",
    "    all_run_metrics.append(run_metrics)\n",
    "    if args.plot:\n",
    "        plot_run_metrics(run_save_dir, args.name, run_id, args.num_cycles, run_metrics)\n",
    "\n",
    "# -- Save all metrics to CSV --\n",
    "summary_csv = os.path.join(args.save_dir, \"summary_all_runs.csv\")\n",
    "df = pd.DataFrame(all_run_metrics)\n",
    "columns = [\"run_id\"] + [\n",
    "    f\"{metric}{cycle_suffix}\"\n",
    "    for cycle_suffix in [f\"_{i}\" for i in range(args.num_cycles + 1)]\n",
    "    for metric in [\"cycle_iptm\", \"cycle_plddt\", \"cycle_iplddt\", \"cycle_alanine\", \"cycle_seq\"]\n",
    "]\n",
    "columns = [col.replace(\"cycle_\", f\"cycle_{i}_\") if \"cycle_\" in col else col for i in range(args.num_cycles + 1) for col in columns if f\"_{i}_\" in col or col == \"run_id\"]\n",
    "columns = sorted(set(columns), key=columns.index)  # keep order, remove dupes\n",
    "columns.extend([\"best_iptm\", \"best_cycle\", \"best_plddt\", \"best_seq\"])\n",
    "\n",
    "for col in columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "df = df[[c for c in columns if c in df.columns]]\n",
    "df.to_csv(summary_csv, index=False)\n",
    "print(f\"\\n‚úÖ All run/cycle metrics saved to {summary_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b19c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title ‚öôÔ∏è Optional: Downstream Validation (Requires External Setup)\n",
    "# # Determine target type\n",
    "# from utils.alphafold_utils import run_alphafold_step\n",
    "# from utils.pyrosetta_utils import run_rosetta_step\n",
    "\n",
    "# target_type = \"protein\"\n",
    "# if args.nucleic_seq:\n",
    "#     target_type = \"nucleic\"\n",
    "# elif args.ligand_smiles or args.ligand_ccd:\n",
    "#     target_type = \"small_molecule\"\n",
    "\n",
    "# success_dir = os.path.join(args.save_dir, \"1_af3_rosetta_validation\")\n",
    "# high_iptm_yaml_dir = os.path.join(args.save_dir, \"high_iptm_yaml\")\n",
    "\n",
    "# # AlphaFold step\n",
    "# af_output_dir, af_output_apo_dir, af_pdb_dir, af_pdb_dir_apo = run_alphafold_step(\n",
    "#     high_iptm_yaml_dir,\n",
    "#     args.alphafold_dir,\n",
    "#     args.af3_docker_name,\n",
    "#     args.af3_database_settings,\n",
    "#     args.hmmer_path,\n",
    "#     success_dir,\n",
    "#     args.work_dir,\n",
    "#     binder_id=args.binder_chain,\n",
    "#     gpu_id=args.gpu_id,\n",
    "#     high_iptm=True,\n",
    "#     use_msa_for_af3=args.use_msa_for_af3,\n",
    "# )\n",
    "\n",
    "# # Rosetta step\n",
    "# run_rosetta_step(\n",
    "#     success_dir,\n",
    "#     af_pdb_dir,\n",
    "#     af_pdb_dir_apo,\n",
    "#     binder_id=args.binder_chain,\n",
    "#     target_type=target_type,\n",
    "# )\n",
    "\n",
    "# print(\"‚úÖ Pipeline execution complete. Check results in the output directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteinhunter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
